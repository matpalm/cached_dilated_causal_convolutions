{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a73d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cmsisdsp as dsp\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1417389",
   "metadata": {},
   "source": [
    "# part 1; standalone convolution running for Kx1 followed by 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  # required for running through keras layer\n",
    "\n",
    "IN_D = 2      # input depth\n",
    "K = 3         # kernel size for c1\n",
    "C1_OUT_D = 4  # output depth of first Kx1 conv\n",
    "C2_OUT_D = 5  # output depth of second 1x1 conv\n",
    "\n",
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "x = np.random.random((K, IN_D))    # K time series, feature depth IN_DIM\n",
    "batched_x = np.expand_dims(x, axis=0)\n",
    "x.shape, batched_x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ef91f",
   "metadata": {},
   "source": [
    "## v1; conv with no bias or activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12579138",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, use_bias=False, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f05da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(c1d.weights) == 1  # just kernel\n",
    "kernel = c1d.weights[0].numpy()\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "kernel.shape, kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe01ab0",
   "metadata": {},
   "source": [
    "so now let's run this convolution explicitly using mat muls.\n",
    "\n",
    "using einsum it'd easy; we could ask for all three matmuls to do be done\n",
    "and then reduce over K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dea0c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42319987, -0.08421276, -0.09528882,  0.29867487])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ki,kij->j', x, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b894f",
   "metadata": {},
   "source": [
    "but, we don't have einsum....\n",
    "\n",
    "note: it's also doable as a batched matmul by introducing a dummy axis into X to denote that we want the K matmuls to be done before the sum reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4586c651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42319987, -0.08421276, -0.09528882,  0.29867487])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.reshape((K, 1, IN_D))\n",
    "# recall kernel is (K, IN_D, OUT_D)\n",
    "\n",
    "result = np.matmul(x2, kernel)  # (K, 1, OUT_D)\n",
    "result.squeeze().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee24ebc",
   "metadata": {},
   "source": [
    "so though we don't have the matmul op this is the approach we'll take; 3 seperate (1, IN_D).(IN_D, OUT_D) mat muls that we accumulate into a result. \n",
    "\n",
    "for reference let's look at the three intermediate results before the summing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8bb85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01432191, -0.00617941,  0.15022187,  0.21971583],\n",
       "       [ 0.13714525, -0.20185   ,  0.10646991, -0.083494  ],\n",
       "       [ 0.27173271,  0.12381665, -0.3519806 ,  0.16245304]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(x2, kernel).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4889890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4231999 , -0.08421277, -0.09528881,  0.29867488], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(intermediate_result, result)    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4264a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(result, keras_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d6e1e",
   "metadata": {},
   "source": [
    "## v2; convolution with bias ( but still no activation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db433233",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "             use_bias=True, bias_initializer='RandomNormal',\n",
    "             activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106f0f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4251941 , -0.07354339, -0.01509508,  0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243b277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel (3, 2, 4) [[[ 0.18940407  0.0069387   0.08696932  0.32015443]\n",
      "  [-0.41096127 -0.03848475  0.31331038 -0.01139957]]\n",
      "\n",
      " [[ 0.21257627 -0.249879    0.1776231  -0.32037094]\n",
      "  [ 0.16129082 -0.26330617  0.12003279 -0.01962107]]\n",
      "\n",
      " [[ 0.4214204   0.51079106 -0.46706867  0.0686931 ]\n",
      "  [-0.07436943 -0.57593465 -0.0376718   0.26714432]]]\n",
      "bias (4,) [0.00199423 0.01066937 0.08019374 0.02654888]\n"
     ]
    }
   ],
   "source": [
    "assert len(c1d.weights) == 2  # kernel and bias now\n",
    "\n",
    "kernel = c1d.weights[0].numpy()\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "print(\"kernel\", kernel.shape, kernel)\n",
    "\n",
    "bias = c1d.weights[1].numpy()\n",
    "assert bias.shape == (C1_OUT_D, )\n",
    "print(\"bias\", bias.shape, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff80029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4251941 , -0.07354339, -0.01509507,  0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert bias.shape == (C1_OUT_D,)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(result, intermediate_result)\n",
    "    \n",
    "# add bias    \n",
    "result = dsp.arm_add_f32(result, bias)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e392ed5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(result, keras_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7cefd",
   "metadata": {},
   "source": [
    "## v3 with bias and relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "080f7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "             use_bias=True, bias_initializer='RandomNormal',\n",
    "             activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a018a2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4251941 , 0.        , 0.        , 0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272a0629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4251941 , 0.        , 0.        , 0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert bias.shape == (C1_OUT_D,)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(result, intermediate_result)\n",
    "\n",
    "# add bias\n",
    "result = dsp.arm_add_f32(result, bias) \n",
    "\n",
    "# apply relu\n",
    "# looks like the most effecient will be to use MAX ?\n",
    "# see https://github.com/ARM-software/CMSIS-NN/blob/main/Source/ActivationFunctions/arm_relu6_s8.c\n",
    "# val = MAX(val, 0.0);\n",
    "result = np.maximum(result, 0)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6641f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(result, keras_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289a7fd",
   "metadata": {},
   "source": [
    "## v4; conv1D & additional 1x1 conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed25db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d1 = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "              use_bias=True, bias_initializer='RandomNormal',\n",
    "              activation='relu')\n",
    "c1d2 = Conv1D(filters=C2_OUT_D, kernel_size=1, \n",
    "              use_bias=True, bias_initializer='RandomNormal',\n",
    "              activation='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a887f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.31180638, 0.        , 0.28677797, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d2(c1d1(batched_x)).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C2_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "088f6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_kernel, c1_bias = c1d1.weights\n",
    "c2_kernel, c2_bias = c1d2.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4045644",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "\n",
    "assert c1_kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert c1_bias.shape == (C1_OUT_D,)\n",
    "assert c2_kernel.shape == (1, C1_OUT_D, C2_OUT_D)\n",
    "assert c2_bias.shape == (C2_OUT_D,)\n",
    "\n",
    "def apply(x, c1_kernel, c1_bias, c2_kernel, c2_bias):\n",
    "    # apply first Kx1 convolution\n",
    "    c1_result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "    c1_result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "    for k in range(K):\n",
    "        x_mi = x[k:k+1,:]\n",
    "        assert x_mi.shape == (1, IN_D)\n",
    "        kernel_mi = c1_kernel[k]\n",
    "        assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "        _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "        c1_result = dsp.arm_add_f32(c1_result, intermediate_result)\n",
    "    # add bias and apply RELU\n",
    "    c1_result = dsp.arm_add_f32(c1_result, c1_bias) \n",
    "    c1_result = np.maximum(c1_result, 0)\n",
    "\n",
    "    # apply second 1x1 convolution\n",
    "    x_mi = c1_result\n",
    "    x_mi = x_mi.reshape((1, C1_OUT_D))\n",
    "    #assert x_mi.shape == (1, OUT_D), x_mi.shape\n",
    "    kernel_mi = c2_kernel[0]\n",
    "    assert kernel_mi.shape == (C1_OUT_D, C2_OUT_D), kernel_mi.shape\n",
    "    _status, c2_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    # add bias and apply RELU\n",
    "    c2_result = dsp.arm_add_f32(c2_result, c2_bias) \n",
    "    c2_result = np.maximum(c2_result, 0)\n",
    "    return c2_result\n",
    "\n",
    "result = apply(x, c1_kernel, c1_bias, c2_kernel, c2_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dd05644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.31180638, 0.        , 0.28677797, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d87e1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(result, keras_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e80a6",
   "metadata": {},
   "source": [
    "## v5; same thing but with inspection of kernels for sizing\n",
    "\n",
    "in prep for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "731e4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [0.         0.31180638 0.         0.28677797 0.        ]\n",
      "all_close True\n"
     ]
    }
   ],
   "source": [
    "# assert x.shape == (K, IN_D)\n",
    "\n",
    "# assert c1_kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "# assert c1_bias.shape == (C1_OUT_D,)\n",
    "# assert c2_kernel.shape == (1, C1_OUT_D, C2_OUT_D)\n",
    "# assert c2_bias.shape == (C2_OUT_D,)\n",
    "\n",
    "class Block(object):\n",
    "    def __init__(self, c1_kernel, c1_bias, c2_kernel, c2_bias):\n",
    "\n",
    "        assert len(c1_kernel.shape) == 3\n",
    "        assert len(c1_bias.shape) == 1    \n",
    "        assert len(c2_kernel.shape) == 3\n",
    "        assert len(c2_bias.shape) == 1\n",
    "\n",
    "        self.k = c1_kernel.shape[0]\n",
    "        self.in_d = c1_kernel.shape[1]\n",
    "        self.c1_out_d = c1_kernel.shape[2]        \n",
    "        assert c1_bias.shape[0] == self.c1_out_d\n",
    "        \n",
    "        assert c2_kernel.shape[0] == 1\n",
    "        assert c2_kernel.shape[1] == self.c1_out_d\n",
    "        self.c2_out_d = c2_kernel.shape[2]\n",
    "        assert c2_bias.shape[0] == self.c2_out_d\n",
    "        \n",
    "        self.c1_kernel = c1_kernel\n",
    "        self.c1_bias = c1_bias\n",
    "        self.c2_kernel = c2_kernel\n",
    "        self.c2_bias = c2_bias\n",
    "\n",
    "    def apply(self, x):\n",
    "        # apply first Kx1 convolution\n",
    "        c1_result = np.empty((1, self.c1_out_d), dtype=np.float32)\n",
    "        c1_result = dsp.arm_fill_f32(0, self.c1_out_d)\n",
    "        for k in range(self.k):\n",
    "            x_mi = x[k:k+1,:]\n",
    "            assert x_mi.shape == (1, self.in_d)\n",
    "            kernel_mi = c1_kernel[k]\n",
    "            assert kernel_mi.shape == (self.in_d, self.c1_out_d)\n",
    "            _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "            c1_result = dsp.arm_add_f32(c1_result, intermediate_result)\n",
    "        # add bias and apply RELU\n",
    "        c1_result = dsp.arm_add_f32(c1_result, self.c1_bias) \n",
    "        c1_result = np.maximum(c1_result, 0)\n",
    "\n",
    "        # apply second 1x1 convolution\n",
    "        x_mi = c1_result\n",
    "        x_mi = x_mi.reshape((1, self.c1_out_d))\n",
    "        #assert x_mi.shape == (1, OUT_D), x_mi.shape\n",
    "        kernel_mi = self.c2_kernel[0]\n",
    "        #assert kernel_mi.shape == (self.c1_out_d, self.c2_out_d), kernel_mi.shape\n",
    "        _status, c2_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "        # add bias and apply RELU\n",
    "        c2_result = dsp.arm_add_f32(c2_result, self.c2_bias) \n",
    "        c2_result = np.maximum(c2_result, 0)\n",
    "        return c2_result\n",
    "\n",
    "layer0 = Block(c1_kernel, c1_bias, c2_kernel, c2_bias)\n",
    "result = layer0.apply(x)\n",
    "\n",
    "print(\"result\", result)\n",
    "print(\"all_close\", np.all(np.isclose(result, keras_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fb01f",
   "metadata": {},
   "source": [
    "# part2, caching for streaming \n",
    "\n",
    "ok. so now we have a little block that can run a Kx1 conv followed by another mixing MLP like 1x1 convolution\n",
    "\n",
    "first construct a full keras model and test it on a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "records_long = []\n",
    "records_wide = []\n",
    "n = 0\n",
    "for line in open('../serial_dump_from_daisy.txt', 'r'):\n",
    "    try:\n",
    "        if line.startswith('b'): \n",
    "            cv = float(line.split(\" \")[2])\n",
    "        else:\n",
    "            in_v, out_v = map(float, line.split(\" \"))\n",
    "            records_long.append((n, 'cv', cv))\n",
    "            records_long.append((n, 'in_v', in_v))\n",
    "            records_long.append((n, 'out_v', out_v))\n",
    "            records_wide.append((n, cv, in_v, out_v))\n",
    "            n += 1\n",
    "    except Exception as e:\n",
    "        print(f\"? [{line.strip()}] ({str(e)})\")\n",
    "df_long = pd.DataFrame(records_long, columns=['n', 'name', 'val'])\n",
    "df_wide = pd.DataFrame(records_wide, columns=['n', 'cv', 'in_v', 'out_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9327c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(df_wide, x='n', y='cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfe57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(df_long[11000:13000], x='n', y='val', hue='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf17433",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = np.array(df_wide['cv'])\n",
    "in_vs = np.array(df_wide['in_v'])\n",
    "x = np.stack([cvs, in_vs]).transpose()\n",
    "\n",
    "y_true = np.expand_dims(np.array(df_wide['out_v']), -1)\n",
    "\n",
    "split = int(len(x) * 0.8)\n",
    "\n",
    "print(split, cvs.shape, in_vs.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = x[:split], y_true[:split]\n",
    "test_x, test_y = x[split:], y_true[split:]\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQ_LEN = 20\n",
    "TEST_SEQ_LEN = 9   # this comes from the model; kernel_size=3 and 2 dilations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7242fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "IN_D = 2        # input depth\n",
    "K = 3           # kernel size for c1\n",
    "C1_FILTERS = 4  # filters for first layer Kx1 and 1x1 convs\n",
    "C2_FILTERS = 8  # filters for second layer Kx1 and 1x1 convs\n",
    "\n",
    "def create_dilated_model(seq_len, all_outputs=False):\n",
    "    inp = Input((seq_len, 2))\n",
    "    c1a_output = Conv1D(name='c1a', filters=C1_FILTERS, kernel_size=3, dilation_rate=1, \n",
    "                        padding='causal', activation='relu')(inp)\n",
    "    c1b_output = Conv1D(name='c1b', filters=C1_FILTERS, kernel_size=1, strides=1,\n",
    "                        activation='relu')(c1a_output)\n",
    "    c2a_output = Conv1D(name='c2a', filters=C2_FILTERS, kernel_size=3, dilation_rate=3, \n",
    "                        padding='causal', activation='relu')(c1b_output)\n",
    "    c2b_output = Conv1D(name='c2b', filters=C2_FILTERS, kernel_size=1, strides=1,\n",
    "                        activation='relu')(c2a_output)\n",
    "    y_pred = Conv1D(name='y_pred', filters=1, kernel_size=1, strides=1,\n",
    "                    activation=None)(c2b_output)    \n",
    "    if all_outputs:\n",
    "        model = Model(inp, [c1a_output, c1b_output, c2a_output, c2b_output, y_pred])\n",
    "    else:\n",
    "        model = Model(inp, y_pred)        \n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# def create_strided_model(seq_len, all_outputs=False):\n",
    "#     inp = Input((seq_len, 2))\n",
    "#     c1a_output = Conv1D(name='c1a', filters=C1_FILTERS, kernel_size=3, strides=3, \n",
    "#                        activation='relu')(inp)\n",
    "#     c1b_output = Conv1D(name='c1b', filters=C1_FILTERS, kernel_size=1, strides=1,\n",
    "#                        activation='relu')(c1a_output)    \n",
    "#     c2a_output = Conv1D(name='c2a', filters=C2_FILTERS, kernel_size=3, strides=3,\n",
    "#                        )(c1_output)\n",
    "#     c2_output = Flatten()(c2_output)\n",
    "#     y_pred = Dense(name='d', units=1, activation=None)(c2_output)\n",
    "    \n",
    "#     if all_outputs:\n",
    "#         model = Model(inp, [c1_output, c2_output, y_pred])\n",
    "#     else:\n",
    "#         model = Model(inp, y_pred)\n",
    "#     print(model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = create_dilated_model(TRAIN_SEQ_LEN, all_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def gen():    \n",
    "    for i in range(len(train_x)-TRAIN_SEQ_LEN-1):\n",
    "        x = train_x[i:i+TRAIN_SEQ_LEN]\n",
    "        y = train_y[i+1:i+1+TRAIN_SEQ_LEN]\n",
    "        yield x, y  # (S, 2) & (S, 1)\n",
    "                 \n",
    "ds = tf.data.Dataset.from_generator(gen, \n",
    "    output_signature=(tf.TensorSpec(shape=(TRAIN_SEQ_LEN, 2), dtype=tf.float32),\n",
    "                      tf.TensorSpec(shape=(TRAIN_SEQ_LEN, 1), dtype=tf.float32)))\n",
    "ds = ds.cache().shuffle(1000).batch(32)\n",
    "train_model.compile(Adam(1e-4), loss='mse')\n",
    "train_model.fit(ds, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd379648",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = create_dilated_model(TEST_SEQ_LEN, all_outputs=True)\n",
    "test_model.set_weights(train_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756471c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.expand_dims(test_x[10:10+TEST_SEQ_LEN], 0)\n",
    "test_seq.shape, test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = test_model(test_seq)\n",
    "model_out = [v.numpy() for v in model_out]\n",
    "model_out = [v[0] for v in model_out]            # drop batch, which is always 1\n",
    "all_steps_y_pred = model_out[-1]\n",
    "all_steps_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1a_out, c1b_out, c2a_out, c2b_out, y_pred_out = model_out\n",
    "c1a_out.shape, c1b_out.shape, c2a_out.shape, c2b_out.shape, y_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_step_y_pred = all_steps_y_pred[-1,0]\n",
    "final_step_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_y[10+TEST_SEQ_LEN][0]\n",
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ec028",
   "metadata": {},
   "source": [
    "manually run the steps of `def apply(x, c1_kernel, c1_bias, c2_kernel, c2_bias):`\n",
    "\n",
    "to replicate first layer output for last value in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5151fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1a_kernel = test_model.layers[1].weights[0].numpy()\n",
    "c1a_bias = test_model.layers[1].weights[1].numpy()\n",
    "c1b_kernel = test_model.layers[2].weights[0].numpy()\n",
    "c1b_bias = test_model.layers[2].weights[1].numpy()\n",
    "\n",
    "assert c1a_kernel.shape == (K, IN_D, C1_FILTERS)\n",
    "assert c1a_bias.shape == (C1_FILTERS,)\n",
    "assert c1b_kernel.shape == (1, C1_FILTERS, C1_FILTERS)\n",
    "assert c1b_bias.shape == (C1_FILTERS,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run first layer\n",
    "layer_0_out_0 = apply(test_seq[0,0:3,:],   # first three elements\n",
    "                      c1a_kernel, c1a_bias, \n",
    "                      c1b_kernel, c1b_bias)\n",
    "layer_0_out_1 = apply(test_seq[0,3:6,:],   # second three elements\n",
    "                      c1a_kernel, c1a_bias, \n",
    "                      c1b_kernel, c1b_bias)\n",
    "layer_0_out_2 = apply(test_seq[0,6:9,:],   # last three elements\n",
    "                      c1a_kernel, c1a_bias, \n",
    "                      c1b_kernel, c1b_bias)\n",
    "\n",
    "layer_0_out_0, layer_0_out_1, layer_0_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09876dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to outputs from keras model\n",
    "\n",
    "c1b_out[2], c1b_out[5], c1b_out[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isclose(\n",
    "    np.stack([layer_0_out_0, layer_0_out_1, layer_0_out_2]),\n",
    "    np.stack([c1b_out[2], c1b_out[5], c1b_out[8]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae955c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run second layer\n",
    "\n",
    "c2a_kernel = test_model.layers[3].weights[0].numpy()\n",
    "c2a_bias = test_model.layers[3].weights[1].numpy()\n",
    "c2b_kernel = test_model.layers[4].weights[0].numpy()\n",
    "c2b_bias = test_model.layers[4].weights[1].numpy()\n",
    "\n",
    "assert c2a_kernel.shape == (K, C1_FILTERS, C2_FILTERS)\n",
    "assert c2a_bias.shape == (C2_FILTERS,)\n",
    "assert c2b_kernel.shape == (1, C2_FILTERS, C2_FILTERS)\n",
    "assert c2b_bias.shape == (C2_FILTERS,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c286471",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_layer_1 = np.stack([layer_0_out_0, layer_0_out_1, layer_0_out_2])\n",
    "print(\"input_for_layer_1.shape\", input_for_layer_1.shape)\n",
    "\n",
    "layer_1_out = apply(input_for_layer_1,\n",
    "                    c2a_kernel, c2a_bias, \n",
    "                    c2b_kernel, c2b_bias)\n",
    "print(\"layer_1_out.shape\", layer_1_out.shape)\n",
    "layer_1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2256e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to keras model\n",
    "c2b_out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isclose(\n",
    "    layer_1_out,\n",
    "    c2b_out[-1]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ff198",
   "metadata": {},
   "source": [
    "finally, run the last classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_kernel = test_model.layers[5].weights[0].numpy()\n",
    "classifier_bias = test_model.layers[5].weights[1].numpy()\n",
    "\n",
    "classifier_kernel.shape, classifier_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"layer_1_out\", layer_1_out.shape)\n",
    "print(\"classifier_kernel\", classifier_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ddedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = np.dot(layer_1_out, classifier_kernel.squeeze()) + classifier_bias\n",
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_step_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(\n",
    "    final_prediction,\n",
    "    final_step_y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e7203",
   "metadata": {},
   "source": [
    "so it works to run `apply` three times to get the output for layer0. \n",
    "and then run `apply` one more time on that output to get the output from layer1\n",
    "and finally a simple classifier.\n",
    "\n",
    "now to run in a streaming way using a cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
