{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a73d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cmsisdsp as dsp\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c22f5d",
   "metadata": {},
   "source": [
    "# part 1; standalone convolution running for Kx1 followed by 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea86282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2),\n",
       " (1, 3, 2),\n",
       " array([[0.69646919, 0.28613933],\n",
       "        [0.22685145, 0.55131477],\n",
       "        [0.71946897, 0.42310646]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1  # required for running through keras layer\n",
    "\n",
    "IN_D = 2      # input depth\n",
    "K = 3         # kernel size for c1\n",
    "C1_OUT_D = 4  # output depth of first Kx1 conv\n",
    "C2_OUT_D = 5  # output depth of second 1x1 conv\n",
    "\n",
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "x = np.random.random((K, IN_D))    # K time series, feature depth IN_DIM\n",
    "batched_x = np.expand_dims(x, axis=0)\n",
    "x.shape, batched_x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d39ad6",
   "metadata": {},
   "source": [
    "## v1; conv with no bias or activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12579138",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, use_bias=False, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f05da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 13:34:51.521012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-03 13:34:51.540921: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.4231999 , -0.08421277, -0.09528882,  0.29867488], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c4cc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 4),\n",
       " array([[[ 0.18940407,  0.0069387 ,  0.08696932,  0.32015443],\n",
       "         [-0.41096127, -0.03848475,  0.31331038, -0.01139957]],\n",
       " \n",
       "        [[ 0.21257627, -0.249879  ,  0.1776231 , -0.32037094],\n",
       "         [ 0.16129082, -0.26330617,  0.12003279, -0.01962107]],\n",
       " \n",
       "        [[ 0.4214204 ,  0.51079106, -0.46706867,  0.0686931 ],\n",
       "         [-0.07436943, -0.57593465, -0.0376718 ,  0.26714432]]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(c1d.weights) == 1  # just kernel\n",
    "kernel = c1d.weights[0].numpy()\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "kernel.shape, kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe01ab0",
   "metadata": {},
   "source": [
    "so now let's run this convolution explicitly using mat muls.\n",
    "\n",
    "using einsum it'd easy; we could ask for all three matmuls to do be done\n",
    "and then reduce over K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dea0c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42319987, -0.08421276, -0.09528882,  0.29867487])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ki,kij->j', x, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b894f",
   "metadata": {},
   "source": [
    "but, we don't have einsum....\n",
    "\n",
    "note: it's also doable as a batched matmul by introducing a dummy axis into X to denote that we want the K matmuls to be done before the sum reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4586c651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42319987, -0.08421276, -0.09528882,  0.29867487])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.reshape((K, 1, IN_D))\n",
    "# recall kernel is (K, IN_D, OUT_D)\n",
    "\n",
    "result = np.matmul(x2, kernel)  # (K, 1, OUT_D)\n",
    "result.squeeze().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee24ebc",
   "metadata": {},
   "source": [
    "so though we don't have the matmul op this is the approach we'll take; 3 seperate (1, IN_D).(IN_D, OUT_D) mat muls that we accumulate into a result. \n",
    "\n",
    "for reference let's look at the three intermediate results before the summing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8bb85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01432191, -0.00617941,  0.15022187,  0.21971583],\n",
       "       [ 0.13714525, -0.20185   ,  0.10646991, -0.083494  ],\n",
       "       [ 0.27173271,  0.12381665, -0.3519806 ,  0.16245304]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(x2, kernel).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4889890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4231999 , -0.08421277, -0.09528881,  0.29867488], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(intermediate_result, result)    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdcde9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4231999 , -0.08421277, -0.09528882,  0.29867488], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e4df4",
   "metadata": {},
   "source": [
    "so LGTM\n",
    "\n",
    "## v2; convolution with bias ( but still no activation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb372279",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "             use_bias=True, bias_initializer='RandomNormal',\n",
    "             activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d94d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4251941 , -0.07354339, -0.01509508,  0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853a1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel (3, 2, 4) [[[ 0.18940407  0.0069387   0.08696932  0.32015443]\n",
      "  [-0.41096127 -0.03848475  0.31331038 -0.01139957]]\n",
      "\n",
      " [[ 0.21257627 -0.249879    0.1776231  -0.32037094]\n",
      "  [ 0.16129082 -0.26330617  0.12003279 -0.01962107]]\n",
      "\n",
      " [[ 0.4214204   0.51079106 -0.46706867  0.0686931 ]\n",
      "  [-0.07436943 -0.57593465 -0.0376718   0.26714432]]]\n",
      "bias (4,) [0.00199423 0.01066937 0.08019374 0.02654888]\n"
     ]
    }
   ],
   "source": [
    "assert len(c1d.weights) == 2  # kernel and bias now\n",
    "\n",
    "kernel = c1d.weights[0].numpy()\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "print(\"kernel\", kernel.shape, kernel)\n",
    "\n",
    "bias = c1d.weights[1].numpy()\n",
    "assert bias.shape == (C1_OUT_D, )\n",
    "print(\"bias\", bias.shape, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86dc1b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4251941 , -0.07354339, -0.01509507,  0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert bias.shape == (C1_OUT_D,)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(result, intermediate_result)\n",
    "    \n",
    "# add bias    \n",
    "result = dsp.arm_add_f32(result, bias)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b306948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4251941 , -0.07354339, -0.01509508,  0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d336b",
   "metadata": {},
   "source": [
    "## v3 with bias and relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91424654",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "             use_bias=True, bias_initializer='RandomNormal',\n",
    "             activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d6c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4251941 , 0.        , 0.        , 0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d(batched_x).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C1_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "812f3fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4251941 , 0.        , 0.        , 0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "assert kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert bias.shape == (C1_OUT_D,)\n",
    "\n",
    "result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    kernel_mi = kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    #kernel_mi = dsp.arm_matrix_instance_f32(IN_D, OUT_D, kernel[k])        \n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    result = dsp.arm_add_f32(result, intermediate_result)\n",
    "\n",
    "# add bias\n",
    "result = dsp.arm_add_f32(result, bias) \n",
    "\n",
    "# apply relu\n",
    "# looks like the most effecient will be to use MAX ?\n",
    "# see https://github.com/ARM-software/CMSIS-NN/blob/main/Source/ActivationFunctions/arm_relu6_s8.c\n",
    "# val = MAX(val, 0.0);\n",
    "result = np.maximum(result, 0)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b9e0062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4251941 , 0.        , 0.        , 0.32522374], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327a38c",
   "metadata": {},
   "source": [
    "## v4; conv1D & additional 1x1 conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f530cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "c1d1 = Conv1D(filters=C1_OUT_D, kernel_size=K, \n",
    "              use_bias=True, bias_initializer='RandomNormal',\n",
    "              activation='relu')\n",
    "c1d2 = Conv1D(filters=C2_OUT_D, kernel_size=1, \n",
    "              use_bias=True, bias_initializer='RandomNormal',\n",
    "              activation='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0f55bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.31180638, 0.        , 0.28677797, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y = c1d2(c1d1(batched_x)).numpy()\n",
    "assert keras_y.shape == (BATCH_SIZE, 1, C2_OUT_D)\n",
    "keras_y = keras_y.squeeze()\n",
    "keras_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b38ec017",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_kernel, c1_bias = c1d1.weights\n",
    "c2_kernel, c2_bias = c1d2.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db38876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.31180638, 0.        , 0.28677797, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x.shape == (K, IN_D)\n",
    "\n",
    "assert c1_kernel.shape == (K, IN_D, C1_OUT_D)\n",
    "assert c1_bias.shape == (C1_OUT_D,)\n",
    "assert c2_kernel.shape == (1, C1_OUT_D, C2_OUT_D)\n",
    "assert c2_bias.shape == (C2_OUT_D,)\n",
    "\n",
    "# apply first Kx1 convolution\n",
    "c1_result = np.empty((1, C1_OUT_D), dtype=np.float32)\n",
    "c1_result = dsp.arm_fill_f32(0, C1_OUT_D)\n",
    "for k in range(K):\n",
    "    x_mi = x[k:k+1,:]\n",
    "    assert x_mi.shape == (1, IN_D)\n",
    "    kernel_mi = c1_kernel[k]\n",
    "    assert kernel_mi.shape == (IN_D, C1_OUT_D)\n",
    "    _status, intermediate_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "    c1_result = dsp.arm_add_f32(c1_result, intermediate_result)\n",
    "# add bias and apply RELU\n",
    "c1_result = dsp.arm_add_f32(c1_result, c1_bias) \n",
    "c1_result = np.maximum(c1_result, 0)\n",
    "\n",
    "# apply second 1x1 convolution\n",
    "x_mi = c1_result\n",
    "x_mi = x_mi.reshape((1, C1_OUT_D))\n",
    "#assert x_mi.shape == (1, OUT_D), x_mi.shape\n",
    "kernel_mi = c2_kernel[0]\n",
    "assert kernel_mi.shape == (C1_OUT_D, C2_OUT_D), kernel_mi.shape\n",
    "_status, c2_result = dsp.arm_mat_mult_f32(x_mi, kernel_mi)\n",
    "# add bias and apply RELU\n",
    "c2_result = dsp.arm_add_f32(c2_result, c2_bias) \n",
    "c2_result = np.maximum(c2_result, 0)\n",
    "\n",
    "c2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edcb2948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.31180638, 0.        , 0.28677797, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947ec6d",
   "metadata": {},
   "source": [
    "# part2, caching for streaming \n",
    "\n",
    "ok. so now we have a little block that can run a Kx1 conv followed by another mixing MLP like 1x1 convolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2d9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingCache(object):\n",
    "    pass\n",
    "\n",
    "StreamingCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fe523a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69646919, 0.28613933],\n",
       "       [0.22685145, 0.55131477],\n",
       "       [0.71946897, 0.42310646],\n",
       "       [0.9807642 , 0.68482974],\n",
       "       [0.4809319 , 0.39211752],\n",
       "       [0.34317802, 0.72904971],\n",
       "       [0.43857224, 0.0596779 ],\n",
       "       [0.39804426, 0.73799541],\n",
       "       [0.18249173, 0.17545176],\n",
       "       [0.53155137, 0.53182759],\n",
       "       [0.63440096, 0.84943179],\n",
       "       [0.72445532, 0.61102351]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "SEQ_LEN = 12\n",
    "\n",
    "x = np.random.random((SEQ_LEN, IN_D))\n",
    "x\n",
    "#StreamingCache.accept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a8b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
