{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc932c4-ff4f-404d-b09d-3385c2307647",
   "metadata": {},
   "source": [
    "prototyping of the interpolation data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3605364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import cmsisdsp as dsp\n",
    "import random\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('/home/mat/dev/cached_dilated_causal_convolutions/') \n",
    "\n",
    "# from cmsisdsp_py_version.block import Block\n",
    "# from cmsisdsp_py_version.keras_model import create_dilated_model, create_strided_model\n",
    "# from cmsisdsp_py_version.cached_block_model import CachedBlockModel, Regression\n",
    "# from cmsisdsp_py_version.rolling_cache import RollingCache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043225af-f393-4131-8ab5-4609762016cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname, w0n, w1n, w2n, invert_waves=[]):\n",
    "    df_w = pd.read_csv(fname, sep=' ', names=['tri', w0n, w1n, w2n])\n",
    "    df_w['n'] = range(len(df_w))\n",
    "    for w in invert_waves:\n",
    "        df_w[w] *= -1\n",
    "    df_l = df_w.melt(id_vars='n', value_vars=['tri', w0n, w1n, w2n])\n",
    "    return df_w, df_l\n",
    "    \n",
    "D = '/data2/cached_dilated_causal_convolutions/2d_embed_interp/wide_freq_range/24kHz'\n",
    "tsrq_df_w, tsrq_df_l = parse(f\"{D}/tri_sine_ramp_square.ssv\", 'sine', 'ramp', 'square')\n",
    "trqz_df_w, trqz_df_l = parse(f\"{D}/tri_ramp_square_zigzag.ssv\", 'ramp', 'square', 'zigzag', invert_waves=['ramp'])\n",
    "tqzs_df_w, tqzs_df_l = parse(f\"{D}/tri_square_zigzag_sine.ssv\", 'square', 'zigzag', 'sine', invert_waves=['sine', 'square'])\n",
    "tzsr_df_w, tzsr_df_l = parse(f\"{D}/tri_zigzag_sine_ramp.ssv\", 'zigzag', 'sine', 'ramp', invert_waves=['sine', 'zigzag'])\n",
    "\n",
    "# tsrq_a = tsrq_df_w.to_numpy()\n",
    "# tqzs_a = tqzs_df_w.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece2d23-3301-4fac-8e4f-b64cfe425278",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tsrq_df_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e57de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, fname in [(tsrq_df_l, '0_tsrq'), (trqz_df_l, '1_trqz'), \n",
    "                  (tqzs_df_l, '2_tqzs'), (tzsr_df_l, '3_tzsr')]:\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    offset = 5500\n",
    "    width = 500\n",
    "    #df = tsrq_df_l\n",
    "    window = (df['n']>offset) & (df['n']<offset+width)\n",
    "    sns.lineplot(df[window], x='n', y='value', hue='variable')\n",
    "    plt.savefig(fname)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d33be-4972-4dc3-9629-bc56451b1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in range(600_000 // 50_000):    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    offset = o * 50_000\n",
    "    width = 500\n",
    "    df = tzsr_df_l\n",
    "    window = (df['n']>offset) & (df['n']<offset+width)\n",
    "    sns.lineplot(df[window], x='n', y='value', hue='variable')\n",
    "    fname = f\"CHECK_{o:05d}.png\"\n",
    "    plt.savefig(fname)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e473a8-e82d-4119-9169-2e97ca580cb7",
   "metadata": {},
   "source": [
    "now we code picking a random point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc9365-85ea-480a-8192-b54066ecadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_to_embed_pt(w):\n",
    "    return {\n",
    "        'sine': np.array([-1, -1]),\n",
    "        'ramp': np.array([-1, 1]),\n",
    "        'square': np.array([1, 1]),\n",
    "        'zigzag': np.array([1, -1])\n",
    "    }[w]\n",
    "    \n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def parse(fname, w0n, w1n, w2n):\n",
    "    df_w = pd.read_csv(fname, sep=' ', names=['tri', w0n, w1n, w2n])\n",
    "    df_w['n'] = range(len(df_w))\n",
    "    #df_l = df_w.melt(id_vars='n', value_vars=['tri', w0n, w1n, w2n])\n",
    "    return df_w.to_numpy() #, df_l\n",
    "    \n",
    "class WaveData(object):\n",
    "    \n",
    "    def __init__(self, wave0, wave1, data, pad_to_size, rescaling_factor):\n",
    "        assert data.shape[1] == 3  # triangle + 2 waves\n",
    "        self.wave0 = wave0\n",
    "        self.wave1 = wave1\n",
    "        self.embed_pt0 = wave_to_embed_pt(wave0)\n",
    "        self.embed_pt1 = wave_to_embed_pt(wave1)\n",
    "        self.data = data\n",
    "        self.pad_to_size = pad_to_size\n",
    "        self.rescaling_factor = rescaling_factor\n",
    "\n",
    "    def sample(self, alpha, seq_len):\n",
    "        \n",
    "        # sample rows\n",
    "        max_offset = len(self.data) - seq_len - 1\n",
    "        random_offset = random.randint(0, max_offset)\n",
    "        sample = self.data[random_offset:(random_offset+seq_len)]\n",
    "        #print(\"sample\", sample.shape)\n",
    "        \n",
    "        # interpolate sample\n",
    "        interpolated_sample = (alpha * sample[:, 1]) + ((1-alpha) * sample[:, 2])\n",
    "        \n",
    "        # smooth with rolling average; can have some sharp boundaries\n",
    "        # note: we need to pad to restore length ( do so with first element )\n",
    "        N = 10\n",
    "        interpolated_sample = moving_average(interpolated_sample, n=N)\n",
    "        interpolated_sample = np.concatenate([[interpolated_sample[0]] * (N-1), interpolated_sample])\n",
    "\n",
    "        # interpolate the embed points with the same alphas\n",
    "        #print(\"self.embed_pt0\", self.embed_pt0)\n",
    "        #print(\"self.embed_pt1\", self.embed_pt1)\n",
    "        #print(\"alpha\", alpha)\n",
    "        interpolated_embed_pt = ( alpha * self.embed_pt0) + ((1-alpha) * self.embed_pt1)\n",
    "        #print(\"interpolated_embed_pt\", interpolated_embed_pt)\n",
    "        interpolated_e0, interpolated_e1 = interpolated_embed_pt\n",
    "        \n",
    "        x = np.zeros((len(sample), self.pad_to_size), dtype=float)\n",
    "        x[:, 0] = sample[:, 0] * self.rescaling_factor\n",
    "        x[:, 1] = interpolated_e0 * self.rescaling_factor\n",
    "        x[:, 2] = interpolated_e1 * self.rescaling_factor\n",
    "        \n",
    "        y = np.zeros((len(sample), self.pad_to_size), dtype=float)\n",
    "        y[:, 0] = interpolated_sample * self.rescaling_factor\n",
    "        \n",
    "        return x, y        \n",
    "\n",
    "    def as_tf_dataset(self, seq_len, max_samples):\n",
    "\n",
    "        def gen():            \n",
    "            num_samples_emitted = 0\n",
    "            while True:\n",
    "                yield self.sample(alpha=0.0, seq_len=seq_len)\n",
    "                yield self.sample(alpha=1.0, seq_len=seq_len)\n",
    "                yield self.sample(alpha=random.random(), seq_len=seq_len)\n",
    "                num_samples_emitted += 3\n",
    "                if num_samples_emitted > max_samples:\n",
    "                    return\n",
    "        \n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen, output_signature=(\n",
    "                tf.TensorSpec(shape=(seq_len, self.pad_to_size), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(seq_len, self.pad_to_size), dtype=tf.float32)))\n",
    "\n",
    "\n",
    "class Embed2DInterpolatedWaveFormData(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                root_dir,\n",
    "                rescaling_factor=1,\n",
    "                pad_size=8):\n",
    "\n",
    "        #D = \n",
    "        tsrq_a = parse(f\"{root_dir}/tri_sine_ramp_square.ssv\", 'sine', 'ramp', 'square')\n",
    "        tqzs_a = parse(f\"{root_dir}/tri_square_zigzag_sine.ssv\", 'square', 'zigzag', 'sine')\n",
    "\n",
    "        self.tsr = WaveData('sine', 'ramp',   tsrq_a[:,[0,1,2]], \n",
    "                            pad_to_size=pad_size, rescaling_factor=rescaling_factor)\n",
    "        self.trq = WaveData('ramp', 'square', tsrq_a[:,[0,2,3]], \n",
    "                            pad_to_size=pad_size, rescaling_factor=rescaling_factor)                            \n",
    "        self.tqz = WaveData('square', 'zigzag', tqzs_a[:,[0,1,2]], \n",
    "                            pad_to_size=pad_size, rescaling_factor=rescaling_factor)\n",
    "        self.tzs = WaveData('zigzag', 'sine', tqzs_a[:,[0,2,3]], \n",
    "                            pad_to_size=pad_size, rescaling_factor=rescaling_factor)\n",
    "\n",
    "        self.all_wave_data = [ self.tsr, self.trq, self.tqz, self.tzs ]\n",
    "\n",
    "    def tf_dataset_for_split(self, split, seq_len, max_samples, waves=None):\n",
    "\n",
    "        assert waves == None, \"TODO\"\n",
    "        \n",
    "        sampled_ds = tf.data.Dataset.sample_from_datasets(\n",
    "            [wd.as_tf_dataset(seq_len, max_samples) for wd in self.all_wave_data]\n",
    "        )\n",
    "\n",
    "        if split == 'train':\n",
    "            sampled_ds = sampled_ds.shuffle(1000)\n",
    "\n",
    "        sampled_ds = sampled_ds.batch(1 if split=='test' else 64)\n",
    "\n",
    "        return sampled_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        \n",
    "def plot(x, y, fname):\n",
    "    assert x.shape == y.shape    \n",
    "    assert x.shape[1] == 8, x.shape\n",
    "    df = pd.DataFrame()\n",
    "    df['x'] = x[:,0]\n",
    "    df['e0'] = x[:,1]\n",
    "    df['e1'] = x[:,2]\n",
    "    df['y'] = y[:,0]\n",
    "    df['n'] = range(len(df))\n",
    "    wide_df = pd.melt(df, id_vars=['n'], value_vars=['x', 'e0', 'e1', 'y'])\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    p = sns.lineplot(wide_df, x='n', y='value', hue='variable')\n",
    "    p.set_ylim((-2, 2))\n",
    "    plt.savefig(fname)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "data = Embed2DInterpolatedWaveFormData(\n",
    "    root_dir='/data2/cached_dilated_causal_convolutions/2d_embed_interp/low_freq_range/24kHz')\n",
    "\n",
    "for x, y in data.tf_dataset_for_split('train', seq_len=500, max_samples=100):    \n",
    "    print(x.shape, y.shape)\n",
    "    for b in range(len(x)):\n",
    "        e0, e1 = x[b,0,1], x[b,0,2]\n",
    "        fname = f\"foo_{b:03d}.{e0}_{e1}.png\"\n",
    "        print(b, fname)\n",
    "        plot(x[b], y[b], fname)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca4f89-807b-4c5a-90fd-f70d6f943b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12049200-0ba1-4572-a1b6-9f2968d9f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tzsr = tzsr_df_w.to_numpy()\n",
    "tzsr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee7a02-5705-4d9c-b692-22b21c8711db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wave_to_embed_pt = { \n",
    "    's': [-1, -1],\n",
    "    'r': [-1, 1],\n",
    "    'z': [1, 1],\n",
    "    'q': [1, -1]\n",
    "}\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "    \n",
    "class WaveData(object):\n",
    "    \n",
    "    def __init__(self, waves, df, pad_to_size):\n",
    "        self.waves = waves\n",
    "        self.wave_to_column = { name: idx for idx, name in enumerate(waves) } \n",
    "        self.df = df\n",
    "        self.pad_to_size = pad_to_size\n",
    "\n",
    "    def _random_interpolation_from_sample(self, sample):\n",
    "        \n",
    "        interp_waves = self.waves[1:]\n",
    "        random.shuffle(interp_waves)\n",
    "#        print(\"interp_waves\", interp_waves)\n",
    "\n",
    "        # choose alpha for interps\n",
    "        alpha1 = random.random()\n",
    "        alpha2 = random.random()\n",
    "#        print(\"alphas\", alpha1, alpha2)\n",
    "\n",
    "        # interpolate samples\n",
    "        # TODO: constant power cross fade would be better here, otherwise we're getting\n",
    "        #       an amplitude drop\n",
    "        interp_columns = [self.wave_to_column[w] for w in interp_waves]\n",
    "#        print(\"interp_columns\", interp_columns)\n",
    "        interpolated_samples = ( alpha1 * sample[:, interp_columns[0]]) + ((1-alpha1) * sample[:, interp_columns[1]])\n",
    "        interpolated_samples = ( alpha2 * sample[:, interp_columns[2]]) + ((1-alpha2) * interpolated_samples)\n",
    "        \n",
    "        # smooth with rolling average; can have some sharp boundaries\n",
    "        # note: we need to pad to restore length ( do so with first element )\n",
    "        N = 10\n",
    "        interpolated_samples = moving_average(interpolated_samples, n=N)        \n",
    "        interpolated_samples = np.concatenate([[interpolated_samples[0]] * (N-1), interpolated_samples])\n",
    "        \n",
    "        # interpolate the embed points with the same alphas\n",
    "        embed_pts = [np.array(wave_to_embed_pt[w]) for w in interp_waves]\n",
    "#        print(\"interp_pts\", interp_pts)\n",
    "        interpolated_embed_pt = ( alpha1 * embed_pts[0]) + ((1-alpha1) * embed_pts[1])\n",
    "#        print(\"interpolated_embed_pt\", interpolated_embed_pt)\n",
    "        interpolated_embed_pt = ( alpha2 * embed_pts[2]) + ((1-alpha2) * interpolated_embed_pt)\n",
    "#        print(\"interpolated_embed_pt\", interpolated_embed_pt)\n",
    "\n",
    "        e0 = interpolated_embed_pt[0]  # e0\n",
    "        e1 = interpolated_embed_pt[1]  # e1\n",
    "        sy = interpolated_samples     \n",
    "       \n",
    "        return e0, e1, sy\n",
    "\n",
    "    \n",
    "    def _random_single_wave(self, sample):\n",
    "        \n",
    "        random_wave = random.choice(self.waves[1:])\n",
    "        random_wave_col = self.wave_to_column[random_wave]\n",
    "        embed_pt = wave_to_embed_pt[random_wave]\n",
    "                \n",
    "        e0 = embed_pt[0]   # e0\n",
    "        e1 = embed_pt[1]   # e1\n",
    "        sy = sample[:, random_wave_col]        \n",
    "        \n",
    "        return e0, e1, sy\n",
    "\n",
    "    \n",
    "    def sample(self, random_interpolation, seq_len):\n",
    "        \n",
    "        max_offset = len(self.df) - seq_len - 1\n",
    "        random_offset = random.randint(0, max_offset)\n",
    "        sample = self.df[random_offset:(random_offset+seq_len)]\n",
    "        \n",
    "        if random_interpolation:\n",
    "            # interpolate randomly between the three waves\n",
    "            e0, e1, sy = self._random_interpolation_from_sample(sample)            \n",
    "        else:\n",
    "            # just pick one of the waves to emit\n",
    "            e0, e1, sy = self._random_single_wave(sample)\n",
    "\n",
    "        x = np.zeros((len(sample), self.pad_to_size), dtype=float)\n",
    "        x[:, 0] = sample[:, 0]\n",
    "        x[:, 1] = e0\n",
    "        x[:, 2] = e1\n",
    "        y = np.zeros((len(sample), self.pad_to_size), dtype=float)  \n",
    "        y[:, 0] = sy\n",
    "        \n",
    "        return x, y        \n",
    "\n",
    "def parse(fname, w0n, w1n, w2n):\n",
    "    df_w = pd.read_csv(fname, sep=' ', names=['tri', w0n, w1n, w2n])\n",
    "    df_w['n'] = range(len(df_w))\n",
    "    df_l = df_w.melt(id_vars='n', value_vars=['tri', w0n, w1n, w2n])\n",
    "    return df_w, df_l\n",
    "\n",
    "tsrq_df_w, tsrq_df_l = parse('../datalogger_firmware/tri_sine_ramp_square.ssv', 'sine', 'ramp', 'square')\n",
    "trqz_df_w, trqz_df_l = parse('../datalogger_firmware/tri_ramp_square_zigzag.ssv', 'ramp', 'square', 'zigzag')\n",
    "tqzs_df_w, tqzs_df_l = parse('../datalogger_firmware/tri_square_zigzag_sine.ssv', 'square', 'zigzag', 'sine')\n",
    "tzsr_df_w, tzsr_df_l = parse('../datalogger_firmware/tri_zigzag_sine_ramp.ssv', 'zigzag', 'sine', 'ramp')\n",
    "\n",
    "def make_dataset(wave_datas, seq_len):\n",
    "    \n",
    "    def gen():\n",
    "        while True:\n",
    "            for wd in wave_datas:\n",
    "                yield wd.sample(random_interpolation=True, seq_len=seq_len)\n",
    "                yield wd.sample(random_interpolation=False, seq_len=seq_len)\n",
    "    \n",
    "    \n",
    "    return tf.data.Dataset.from_generator(\n",
    "            gen, output_signature=(tf.TensorSpec(shape=(seq_len, 8), dtype=tf.float32),\n",
    "                                   tf.TensorSpec(shape=(seq_len, 8), dtype=tf.float32)))    \n",
    "\n",
    "\n",
    "wave_datas = [\n",
    "    WaveData(['t', 's', 'r', 'q'], tsrq_df_w.to_numpy(), pad_to_size=8),\n",
    "    WaveData(['t', 'r', 'q', 'z'], trqz_df_w.to_numpy(), pad_to_size=8),\n",
    "    WaveData(['t', 'q', 'z', 's'], tqzs_df_w.to_numpy(), pad_to_size=8),\n",
    "    WaveData(['t', 'z', 's', 'r'], tzsr_df_w.to_numpy(), pad_to_size=8)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1304f1a-9b2a-48af-ad6e-39c90906edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_dataset(wave_datas, seq_len=1000).batch(20)\n",
    "\n",
    "for x, y in data:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f3d86-746c-4d4c-9df5-a3b148ed1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    fig.clf()\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    print(i, x[i][:5])\n",
    "    ax1.plot(x[i])\n",
    "    ax2.plot(y[i])\n",
    "    ax1.set_ylim((-1, 1))\n",
    "    ax2.set_ylim((-1, 1))\n",
    "    plt.savefig(f\"foo_{i:03d}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00199ded-aca9-404f-9831-a3fea94ac89c",
   "metadata": {},
   "source": [
    "we want to rebuild the dataset from tri, sine, ramp and tri, square, zigzag\n",
    "to (embed0, embed1, tri) -> one of the other waves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fb6a3-0d61-44e6-a9e5-6d5a21c05aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]\n",
    "\n",
    "[x[0]]*5 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b38e0-34af-4059-a22b-39920c56aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tsr_df_w.to_numpy().astype(np.float32)\n",
    "\n",
    "tri_to = {}\n",
    "tri_to['sine'] = {}\n",
    "tri_to['sine']['x'] = np.empty((len(data), 3), dtype=np.float32)\n",
    "tri_to['sine']['x'][:,0] = 0  # x2\n",
    "tri_to['sine']['x'][:,1] = 0  # x3\n",
    "tri_to['sine']['x'][:,2] = data[:,0] # triangle\n",
    "tri_to['sine']['y'] = np.expand_dims(data[:,1], -1) # sine\n",
    "\n",
    "tri_to['ramp'] = {}\n",
    "tri_to['ramp']['x'] = np.empty((len(data), 3), dtype=np.float32)\n",
    "tri_to['ramp']['x'][:,0] = 0  # x2\n",
    "tri_to['ramp']['x'][:,1] = 1  # x3\n",
    "tri_to['ramp']['x'][:,2] = data[:,0] # triangle\n",
    "tri_to['ramp']['y'] = np.expand_dims(data[:,2], -1) # ramp\n",
    "\n",
    "data = tsz_df_w.to_numpy().astype(np.float32)\n",
    "\n",
    "tri_to['square'] = {}\n",
    "tri_to['square']['x'] = np.empty((len(data), 3), dtype=np.float32)\n",
    "tri_to['square']['x'][:,0] = 1  # x2\n",
    "tri_to['square']['x'][:,1] = 0  # x3\n",
    "tri_to['square']['x'][:,2] = data[:,0] # triangle\n",
    "tri_to['square']['y'] = np.expand_dims(data[:,1], -1) # square\n",
    "\n",
    "tri_to['zigzag'] = {}\n",
    "tri_to['zigzag']['x'] = np.empty((len(data), 3), dtype=np.float32)\n",
    "tri_to['zigzag']['x'][:,0] = 1  # x2\n",
    "tri_to['zigzag']['x'][:,1] = 1  # x3\n",
    "tri_to['zigzag']['x'][:,2] = data[:,0] # triangle\n",
    "tri_to['zigzag']['y'] = np.expand_dims(data[:,2], -1) # zigzag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5686d0b-94eb-4890-9cc7-fbf5e4066c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(d):\n",
    "    assert 'x' in d\n",
    "    assert 'y' in d\n",
    "    assert len(d['x']) == len(d['y'])\n",
    "    val_test_split_size = int(len(d['x']) * 0.1)  # 10% for val and test\n",
    "    d['train'] = {}\n",
    "    d['validate'] = {}\n",
    "    d['test'] = {}\n",
    "    for xy in ['x', 'y']:                \n",
    "        d['train'][xy] = d[xy][:-2*val_test_split_size]        \n",
    "        d['validate'][xy] = d[xy][-2*val_test_split_size:-val_test_split_size]        \n",
    "        d['test'][xy] = d[xy][-val_test_split_size:]\n",
    "        d.pop(xy)\n",
    "\n",
    "for wave in ['sine', 'ramp', 'square', 'zigzag']:\n",
    "    split_train_val_test(tri_to[wave])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce28d5-d669-4d27-83a1-1e8fdc8fe907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:,0][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71798f85-c5e4-4f8c-8aea-90e51bd3596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tri_to['ramp']['train']['x'][:,2][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097991e8-c36c-418d-add4-47b9e7608036",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tri_to['ramp']['validate']['y'][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1f49e-cd64-4097-a91b-39a964ee7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tri_to['square']['test']['y'][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tri_to['sine']['train']['y'][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc188ce-aaf9-46ef-af36-e3f6dd563d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tri_to['zigzag']['validate']['y'][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_D = 3    # 2d embedding, (0,1) and core triangle\n",
    "OUT_D = 1   # output wave\n",
    "\n",
    "# kernel size and implied dilation rate\n",
    "K = 4                \n",
    "\n",
    "# filters for Nth layer Kx1 and 1x1 convs\n",
    "# [4, 3, 8, 8] @ 32kHz => 72%\n",
    "# [4, 8, 8, 8] @ 32kHz => 82%\n",
    "# [4, 8, 8, 12] @ 32kHz => 93%\n",
    "# [8, 8, 8, 8] @ 32kHz => TOO MUCH\n",
    "# [4, 4, 4] @ 96kHz => too much :/\n",
    "# [2, 2, 4] @ 96kHz => too much :/\n",
    "# [2, 2, 2] @ 96kHz => too much :/\n",
    "\n",
    "FILTER_SIZES = [4, 4, 4, 4]\n",
    "\n",
    "RECEPTIVE_FIELD_SIZE = K**len(FILTER_SIZES)\n",
    "\n",
    "TEST_SEQ_LEN = RECEPTIVE_FIELD_SIZE\n",
    "TRAIN_SEQ_LEN = RECEPTIVE_FIELD_SIZE * 5\n",
    "\n",
    "print(\"RECEPTIVE_FIELD_SIZE\", RECEPTIVE_FIELD_SIZE)\n",
    "print(\"TRAIN_SEQ_LEN\", TRAIN_SEQ_LEN)\n",
    "print(\"TEST_SEQ_LEN\", TEST_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da061f33-b37f-4f22-9810-78fb7369a6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a8fa1-a9fb-47a7-a742-f77be556b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def masked_mse(y_true, y_pred):    \n",
    "    assert len(y_true.shape) == 3, \"expected (batch, sequence_length, output_dim)\"\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    \n",
    "    # average over elements of y\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)  \n",
    "    \n",
    "    # we want to ignore the first RECEPTIVE_FIELD_SIZE elements of the loss since they \n",
    "    # have been fed with left padded data\n",
    "    mse = mse[:,RECEPTIVE_FIELD_SIZE:]     \n",
    "\n",
    "    # return average over batch and sequence\n",
    "    return tf.reduce_mean(mse)\n",
    "    \n",
    "def dataset_from(x, y, s):\n",
    "    def gen():\n",
    "        idxs = list(range(len(x)-TRAIN_SEQ_LEN-1))  # ~1.3M\n",
    "        random.Random(1337).shuffle(idxs)\n",
    "        if s == 'train':            \n",
    "            idxs = idxs[:20_000]   # 200_000\n",
    "        else:\n",
    "            idxs = idxs[:500]   # 5_000\n",
    "        for i in idxs:\n",
    "            yield x[i:i+TRAIN_SEQ_LEN], y[i+1:i+1+TRAIN_SEQ_LEN]\n",
    "                \n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen, output_signature=(tf.TensorSpec(shape=(TRAIN_SEQ_LEN, IN_D), dtype=tf.float32),\n",
    "                               tf.TensorSpec(shape=(TRAIN_SEQ_LEN, OUT_D), dtype=tf.float32)))\n",
    "    return ds\n",
    "\n",
    "def datasets_for_split(s):\n",
    "    return  [\n",
    "        dataset_from(tri_to[wave][s]['x'], tri_to[wave][s]['y'], s) #.cache() #filename=f\"tf_data_cache_{wave}\")\n",
    "        for wave in ['sine', 'ramp', 'square', 'zigzag']  \n",
    "    ] \n",
    "    \n",
    "train_ds = tf.data.Dataset.sample_from_datasets(datasets_for_split('train'))\n",
    "train_ds = train_ds.batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "validate_ds = tf.data.Dataset.sample_from_datasets(datasets_for_split('validate'))\n",
    "validate_ds = validate_ds.batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
